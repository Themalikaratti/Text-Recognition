# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wfi5lp0WQxRp3-sDF0H3vA0iA8rj4KAs
"""

import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\\Program Files\\Tesseract-OCR\\tesseract.exe"
import matplotlib.pyplot as plt

import cv2

image = cv2.imread('name.jpeg')

print(image)

plt.imshow(image)

image

image2char = pytesseract.image_to_string(image)

print(image2char)

imagebox = pytesseract.image_to_boxes(image)

print(imagebox)

imagebox = pytesseract.image_to_boxes(image)

imageH, imageW,_ = image.shape

image.shape

for boxes in imagebox.splitlines():
    boxes = boxes.split(' ')
    x,y,w,h = int(boxes[1]),int(boxes[2]),int(boxes[3]),int(boxes[4])
    cv2.rectangle(image, (x,imageH-y), (w,imageH-h), (0,0,225),3)

plt.imshow(image)

def read_image(image):
    img = cv2.imread(image)
    return img


    

import cv2
import numpy as np
font_scale = 1.5

font= cv2.FONT_HERSHEY_PLAIN

import cv2
import pytesseract

# Initialize the video capture object
cap = cv2.VideoCapture(1)

# Check if the camera is opened successfully
if not cap.isOpened():
    # If the camera at index 1 is not opened, try opening the default camera (index 0)
    cap = cv2.VideoCapture(0)

# Check if the camera is opened successfully
if not cap.isOpened():
    # If neither camera is opened successfully, raise an IOError
    raise IOError("Cannot open video")

# Counter to control processing frequency
cntr = 0

while True:
    # Read a frame from the video capture
    ret, frame = cap.read()

    # Increment the counter
    cntr += 1

    # Process every 20th frame
    if (cntr % 20) == 0:
        # Get the dimensions of the frame
        imageH, imageW, _ = frame.shape

        # Set region of interest to the whole frame
        x1, y1, w1, h1 = 0, 0, imageH, imageW

        # Perform OCR on the frame
        imagechar = pytesseract.image_to_string(frame)
        imageboxes = pytesseract.image_to_boxes(frame)

        # Iterate over each detected box
        for boxes in imageboxes.splitlines():
            boxes = boxes.split(' ')
            x, y, w, h = int(boxes[1]), int(boxes[2]), int(boxes[3]), int(boxes[4])

            # Draw a rectangle around the detected text region
            cv2.rectangle(frame, (x, imageH - y), (w, imageH - h), (0, 0, 255), 3)

            # Add the detected text as label
            cv2.putText(frame, imagechar, (x1 + int(w1 / 50), y1 + int(h1 / 50)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # Display the frame with text detection
        cv2.imshow('text detection tutorial', frame)

        # Check if 'a' key is pressed to break the loop
        if cv2.waitKey(2) & 0xFF == ord('a'):
            break

# Release the video capture object
cap.release()

# Close all OpenCV windows
cv2.destroyAllWindows()

